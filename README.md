# Projeto 1: Plataforma de An√°lise de Streaming em Tempo Real

## üéØ Sum√°rio Executivo

Este projeto implementa um pipeline de dados de ponta a ponta para a an√°lise em tempo real de eventos de clickstream de um site de e-commerce. A solu√ß√£o ingere eventos de cliques de usu√°rios, processa-os com o Apache Spark para calcular m√©tricas de neg√≥cio em janelas de tempo (contagem de cliques por p√°gina a cada minuto) e persiste os resultados em um banco de dados anal√≠tico (ClickHouse) para visualiza√ß√£o em um dashboard de BI (Metabase). O objetivo √© fornecer insights operacionais com lat√™ncia de segundos, demonstrando uma arquitetura escal√°vel, resiliente e observ√°vel.

## üìà O Desafio de Neg√≥cio

Uma empresa de e-commerce em crescimento precisa de visibilidade imediata sobre como os usu√°rios interagem com sua plataforma. As an√°lises baseadas em lotes (batch) existentes t√™m uma lat√™ncia de horas, o que √© muito lento para responder a tend√™ncias de navega√ß√£o, identificar sess√µes de usu√°rios com problemas ou detectar atividades fraudulentas (bots) em tempo h√°bil. A empresa necessita de uma solu√ß√£o que possa processar dezenas de milhares de eventos por segundo, garantindo ao mesmo tempo a qualidade e a integridade dos dados para a tomada de decis√£o.

## üèóÔ∏è Arquitetura da Solu√ß√£o

A arquitetura foi projetada para ser escal√°vel, resiliente e otimizada para custos, utilizando um modelo de desenvolvimento h√≠brido (local + nuvem). O fluxo de dados segue as melhores pr√°ticas de uma arquitetura de streaming moderna.

> **Nota:** O diagrama final ser√° adicionado ao concluir o projeto.

### üåä Fluxo de Dados

1.  **Gera√ß√£o de Dados:** Um script Python (`data_producer`) simula eventos de clickstream em formato JSON e os publica em um t√≥pico no Apache Kafka.
2.  **Ingest√£o e Buffer:** O Apache Kafka atua como um *message broker* central, recebendo os eventos em tempo real e funcionando como um buffer resiliente que desacopla os produtores dos consumidores.
3.  **Processamento em Stream:** Um job do Apache Spark (`stream_processor`) consome os dados do Kafka em micro-lotes. O processamento ocorre em v√°rias etapas:
    -   **Parsing e Estrutura√ß√£o:** O JSON bruto √© transformado em um DataFrame Spark com um schema bem definido e tipagem forte.
    -   **Valida√ß√£o de Qualidade:** Cada registro √© validado contra regras de neg√≥cio (ex: `user_id` e `page_url` n√£o podem ser nulos).
    -   **Agrega√ß√£o em Janela:** Os dados v√°lidos s√£o agregados em janelas de tempo de 1 minuto (*tumbling windows*). O uso de *watermarking* garante o tratamento correto de dados atrasados e o gerenciamento eficiente do estado da aplica√ß√£o Spark.
4.  **Persist√™ncia:** Os resultados agregados s√£o escritos via JDBC em uma tabela otimizada no ClickHouse, um banco de dados colunar de alta performance ideal para consultas anal√≠ticas.
5.  **Visualiza√ß√£o:** O Metabase se conecta ao ClickHouse para consumir os dados agregados e exibi-los em dashboards interativos, fornecendo a camada de *Business Intelligence* para os stakeholders.

## üõ†Ô∏è Tech Stack (Pilha de Tecnologias)

| Componente | Tecnologia | Justificativa de Neg√≥cio/T√©cnica |
| :--- | :--- | :--- |
| **Gera√ß√£o de Dados** | Python (Faker, kafka-python) | Simula um ambiente de produ√ß√£o realista com dados din√¢micos. |
| **Message Broker** | Apache Kafka | Padr√£o da ind√∫stria para ingest√£o de dados em alto volume e baixa lat√™ncia. Desacopla sistemas e garante resili√™ncia. |
| **Processamento** | Apache Spark (PySpark) | Motor de processamento distribu√≠do ideal para transforma√ß√µes complexas e agrega√ß√µes em streams de dados com alta performance. |
| **Banco de Dados** | ClickHouse | Banco de dados colunar otimizado para escritas em lote e leituras anal√≠ticas (OLAP) extremamente r√°pidas, perfeito para alimentar dashboards. |
| **BI / Visualiza√ß√£o** | Metabase | Ferramenta de BI open-source que permite a cria√ß√£o r√°pida de dashboards e a explora√ß√£o de dados de forma intuitiva. |
| **Infraestrutura** | Docker / Docker Compose | Permite a cria√ß√£o de um ambiente de desenvolvimento local completo e reprodut√≠vel, encapsulando todas as depend√™ncias. |
| **Infra como C√≥digo** | Terraform (Fase Futura) | Automatiza o provisionamento da infraestrutura na nuvem (AWS), garantindo consist√™ncia, reprodutibilidade e controle de vers√£o. |

## üöÄ Guia de Execu√ß√£o Local

Este projeto √© totalmente conteinerizado e gerenciado pelo Docker Compose para uma experi√™ncia de desenvolvimento simplificada.

### ‚úÖ Pr√©-requisitos

-   Windows com WSL2, ou um sistema Linux/macOS
-   Docker e Docker Compose instalados
-   Git

### ‚öôÔ∏è Passos para Execu√ß√£o

1.  **Clone o reposit√≥rio:**
    ```bash
    git clone https://github.com/seu-usuario/seu-repositorio.git
    cd seu-repositorio
    ```

2.  **Permiss√£o de Execu√ß√£o (Apenas na primeira vez):**
    O script de inicializa√ß√£o do ClickHouse precisa de permiss√£o de execu√ß√£o.
    ```bash
    chmod +x ./clickhouse/init-db.sh
    ```

3.  **Inicie toda a infraestrutura:**
    Este comando ir√° iniciar Kafka, Zookeeper, Spark Master/Worker, ClickHouse e Metabase em modo *detached* (-d).
    ```bash
    docker-compose up -d
    ```
    Para verificar o status de todos os servi√ßos, use `docker ps`.

4.  **Acesse as UIs para monitoramento:**
    -   **Spark Master UI:** [http://localhost:8080](http://localhost:8080)
    -   **Metabase UI:** [http://localhost:3000](http://localhost:3000)

5.  **Crie o t√≥pico no Kafka (Apenas na primeira vez ou ap√≥s `down -v`):**
    ```bash
    docker exec -it kafka kafka-topics --create \
      --bootstrap-server kafka:9092 \
      --topic clickstream_events \
      --partitions 1 \
      --replication-factor 1
    ```

6.  **Inicie o produtor de dados (em um novo terminal):**
    ```bash
    python data_producer/data_producer.py
    ```

7.  **Inicie o processador de stream Spark (em outro terminal):**
    O comando `--packages` instrui o Spark a baixar dinamicamente os conectores JDBC e Kafka necess√°rios.
    ```bash
    docker exec -it spark-master spark-submit \
      --packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.4.1,com.clickhouse:clickhouse-jdbc:0.5.0,org.apache.httpcomponents.client5:httpclient5:5.2.1 \
      /app/spark_processor/stream_processor.py
    ```
    Voc√™ ver√° os logs do Spark processando os dados em lotes e confirmando a escrita no ClickHouse.

## üìä Fase 6: Visualiza√ß√£o e Business Intelligence

Nesta fase, o objetivo √© conectar a camada de BI (Metabase) aos dados agregados no ClickHouse para visualizar os resultados do pipeline e extrair valor de neg√≥cio.

### 6.1. Valida√ß√£o do Pipeline e An√°lise Cr√≠tica

Ap√≥s configurar a conex√£o entre o Metabase e o ClickHouse, criamos um dashboard inicial para visualizar a contagem de cliques por p√°gina, com atualiza√ß√£o autom√°tica a cada 15 segundos.

**Resultado Inicial:**

![Dashboard Inicial com Dados Simulados](/real-time-platform/jpeg/graf1.jpg)

**An√°lise Cr√≠tica:**
O dashboard acima confirma que o pipeline de ponta a ponta est√° **tecnicamente funcional**: eventos s√£o gerados, processados pelo Spark e persistidos no ClickHouse, com os resultados sendo exibidos no Metabase em tempo real.

No entanto, ele **falha em gerar insights de neg√≥cio acion√°veis**. Todas as barras do gr√°fico possuem uma contagem de "1". Isso ocorre porque o script `data_producer.py`, em sua vers√£o inicial, utiliza a biblioteca `Faker` para gerar uma URL completamente nova e √∫nica para cada evento. Como resultado, ao agregar os dados em janelas de 1 minuto, cada p√°gina (`page_url`) aparece apenas uma vez, resultando em uma contagem de 1.

### 6.2. Resultado Final e Valor de Neg√≥cio

Ap√≥s refinar o script `data_producer.py` para simular um comportamento de usu√°rio mais realista (com p√°ginas populares recebendo mais tr√°fego), o pipeline passou a gerar agrega√ß√µes significativas. O dashboard final agora fornece insights de neg√≥cio claros e em tempo real.

**Dashboard Final:**

![Dashboard Final com Dados Realistas](/real-time-platform/jpeg/graf2.jpg)

**An√°lise de Valor:**
Este dashboard demonstra o valor de neg√≥cio da solu√ß√£o de ponta a ponta:

*   **Visibilidade Operacional:** Stakeholders podem monitorar quais p√°ginas est√£o com maior engajamento no √∫ltimo minuto.
*   **Tomada de Decis√£o R√°pida:** Anomalias, como uma queda dr√°stica de cliques em p√°ginas cr√≠ticas (ex: `/cart`), podem ser detectadas em segundos, em vez de horas.
*   **Valida√ß√£o de Arquitetura:** O gr√°fico prova que a arquitetura √© capaz de ingerir, processar, agregar e visualizar dados com baixa lat√™ncia, cumprindo o objetivo principal do projeto.

## ‚òÅÔ∏è Fase 7: Implanta√ß√£o na Nuvem com IaC (Terraform)

Com a solu√ß√£o validada localmente, esta fase eleva o projeto a um n√≠vel de produ√ß√£o, automatizando a implanta√ß√£o da infraestrutura na nuvem da AWS usando Terraform. O objetivo √© demonstrar a capacidade de criar um ambiente replic√°vel, escal√°vel e gerenciado como c√≥digo, uma habilidade essencial para qualquer engenheiro de dados s√™nior ou arquiteto de solu√ß√µes.

### 7.1. Configura√ß√£o e Funda√ß√£o da Rede

O primeiro passo na nuvem √© construir uma funda√ß√£o de rede segura e isolada para nossos servi√ßos. Utilizando Terraform, definimos e provisionamos os seguintes recursos:

*   **Provedor AWS e Usu√°rio IAM:** Configura√ß√£o inicial do Terraform para se comunicar com a AWS de forma segura, utilizando um usu√°rio IAM dedicado com permiss√µes espec√≠ficas, em vez do usu√°rio root.
*   **Virtual Private Cloud (VPC):** Cria√ß√£o de uma rede privada (`10.0.0.0/16`) na regi√£o `us-west-2` (Oregon), isolando nossos recursos da internet p√∫blica por padr√£o.
*   **Sub-rede P√∫blica:** Defini√ß√£o de uma sub-rede (`10.0.1.0/24`) dentro da VPC, projetada para hospedar recursos que precisam de acesso √† internet.
*   **Gateway de Internet e Tabela de Rotas:** Configura√ß√£o dos componentes necess√°rios para permitir que os recursos na sub-rede p√∫blica se comuniquem com o mundo exterior, essencial para baixar pacotes e imagens Docker.

Todo o processo √© definido em arquivos `.tf`, garantindo que a infraestrutura seja:
-   **Version√°vel:** Pode ser armazenada no Git, assim como o c√≥digo da aplica√ß√£o.
-   **Reprodut√≠vel:** Pode ser destru√≠da (`terraform destroy`) e recriada (`terraform apply`) com um √∫nico comando, garantindo consist√™ncia.
-   **Documentada:** O pr√≥prio c√≥digo serve como documenta√ß√£o clara da arquitetura da rede.

### 7.2. Pr√≥ximos Passos na Nuvem

Com a funda√ß√£o da rede estabelecida, os pr√≥ximos passos se concentrar√£o em provisionar os componentes da aplica√ß√£o:

1.  **Firewall (Security Groups):** Definir regras de firewall para controlar o tr√°fego de entrada (SSH, portas da aplica√ß√£o) e sa√≠da para o nosso servidor.
2.  **Servidor de Aplica√ß√£o (EC2):** Provisionar uma inst√¢ncia de m√°quina virtual que ir√° hospedar nossa stack Docker (Kafka, Spark, ClickHouse, etc.).
3.  **Configura√ß√£o e Valida√ß√£o:** Automatizar a configura√ß√£o do servidor EC2 para instalar o Docker, clonar nosso projeto e iniciar o pipeline de dados, validando a solu√ß√£o de ponta a ponta no ambiente de nuvem.